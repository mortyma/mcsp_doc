\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}

\usepackage{comment}
\usepackage{hyperref}
\usepackage{cite}
%page boarders
\usepackage[vmargin=3cm, hmargin=3cm]{geometry}
\usepackage{float}
\floatstyle{plaintop}
\usepackage{paralist} %compactitem
\usepackage{fixltx2e} %some latex fixes
\usepackage{microtype} %Subliminal refinements towards typographical perfection
\setlength{\emergencystretch}{2em}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathrsfs} %Support use of the Raph Smithâ€™s Formal Script font in mathematics
\usepackage[sc]{mathpazo} %mathematical fonts
\usepackage{amsfonts}
\usepackage{booktabs}
\usepackage[margin=10pt, font=small, labelfont=bf]{caption}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{color}
\newcommand\todo[1]{\textcolor{red}{TODO: #1}}
\newcommand\load{L_{\mathrm{max}}}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
% within an align* environment, number and label the equation. #1 is the label text to be appended to eqn:
\newcommand\neqn[1]{\numberthis\label{eqn:#1}}

% theorem, lemma, ...
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{theorem}{Theorem}
\newtheorem{assumption}{Assumption}
\newtheorem{definition}{Definition}

% vectors
\newcommand{\vect}[1]{\vec{#1}}

\lstset{
    language=C,
    basicstyle=\ttfamily,
    keywordstyle=\color{OliveGreen},
    commentstyle=\color{Gray},
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    showspaces=false,
    showtabs=false,
    numbers=left,
}

\title{A multi-criteria priority queue for the Pheet task scheduling framework\\
\normalsize Technical report for \\``Project in Software Engineering \& Internet Computing''
}
\author{Martin Kalany, 0825673\\
Vienna University of Technology}

\begin{document}

\maketitle

%scale factor for graphs
\setkeys{Gin}{width=0.5\textwidth}

%R functions for plot generation
<<echo=FALSE, include=FALSE>>=
\SweaveInput{functions.Rnw}
@

\begin{abstract}
\cite{Wimmer14} \todo{abstract}
\end{abstract}

\pagebreak

%TODO
%\tableofcontents


\section{Introduction} \label{sec:intro}
% explain the idea of this work in a couple of sentences. This is for the informed reader.

% Introduce pheet
Pheet\footnote{\url{www.pheet.org}} is an open-source task scheduling framework for shared memory systems   
and is based on the task-parallel programming model, which allows a programmer to explicitly expose the parallelism of an application.
% The build-up for task priorities
Runtime systems based on the task-parallel model typically impose a non-adaptive, application independent execution order on the tasks where the scheduler is unaware of the preferred execution order of the tasks (The tasks are processed in, e.g., LIFO-order).
% The problem with Dijkstra's algorithm
While it has proven to be an efficient strategy for parallelization \todo{citation needed}, this approach has not been particularly useful for the parallelization of algorithms relying on priority queues (such as Dijkstra's famous algorithm for the single-source shortest path problem (SSSP) \cite{Dijkstra59}), since two work pools have to be maintained: 
One is used by the scheduling framework to maintain tasks that are yet to be executed; the other is required by the algorithm itself to determine the execution order of the tasks.

% Priority task scheduling
\emph{Priority task scheduling}, introduced by Wimmer et al.~\cite{WVTCT13}, addresses this problem by making the preferred execution order of tasks known to the scheduler. 
To achieve this, the task scheduler utilizes a concurrent priority queue which fulfills the ordering requirements imposed by the algorithm by assigning discrete priority values to the tasks.
Wimmer \cite{Wimmer14} further states that a scheduler based on the task priority scheduling model allows for an efficient parallel implementation of any algorithm relying on priority queues is possible.
They back up their claim by providing a parallel implementation of Dijkstra's algorithm on top of Pheet, which utilizes a scheduler based on the priority task scheduling model.

% Pareto priorities
In their dissertation \cite{Wimmer14}, they suggest to generalize the idea of priority task scheduling to multi-dimensional (or \emph{Pareto-}) priorities, which would allow for an efficient parallel implementation of e.g., algorithms solving the multi-criteria shortest path problem (MSP)\footnote{Sometimes also called multi-objective shortest path or multi-objective optimization problem} as discussed in \cite{Martins84}.
They outline a different advantage of using multi-dimensional priorities for task scheduling, which is independent of the algorithm that utilizes the scheduler:
Multi-dimensional priorities establish only a partial ordering on the tasks, which gives the scheduler more flexibility in terms of which task to execute next. 

% Our work
In this work, we investigate a potential implementation of such a multi-dimensional priority queue for the Pheet task scheduling framework, which is then used in turn for a parallel algorithm solving the MSP \footnote{This problem was suggested to us by our supervisor Martin Wimmer.}. 

\todo{explain that we compare our priority queue to a solution based on linear combination+one dimensional priority queue,...}


\subsubsection*{Outline} \label{sec:intro:outline}
We give formal definitions of the shortest path problems in Section \ref{sec:shortest_path}.
In Section \ref{sec:pheet}, we provide a general introduction to the Pheet task scheduling framework and a more detailed presentation of the concepts used in Pheet that are relevant for this work.

\todo{...}

\section{Bits and pieces}

% plug-in architecture
Pheet's flexible plug-in architecture based on C++ templates allows for any component in the task scheduling system to be replaced by a different implementation.
% Pheet benchmark suite & performance counters
Additionally, Pheet provides a set of micro-benchmarks (that aim to evaluate specific aspects of the scheduling framework) and fine grained performance counters (that provide detailed insight into the scheduler and supporting data structures). 
% Framework for evaluation of scheduler components
Overall, Pheet is a suitable framework for the evaluation and comparison of scheduler components.

% reference Martin's dissertation
A detailed introduction to Pheet and the research based on it can be found in the dissertation of Martin Wimmer \cite{Wimmer14}. 

% work pool pattern
The task-parallel model is based on the \emph{work pool pattern}:
Informally, a task is a small amount of work that is to be executed sequentially.
All such tasks are stored in a work pool.
As soon as a processor is ready to execute work, it retrieves a task that is ready to be executed from the work pool.
A task may itself create additional tasks that are then stored in the work pool.
A famous algorithm based on the work pool pattern is Dijkstra's algorithm \cite{Dijkstra59} for the SSSP:


% task-parallel model
Additionally, the programmer defines dependencies between the task which ensure that a task is not executed before all required prerequisites are met; if, however, two tasks do not depend on each other, they may be executed in parallel.

% pareto priority queue
\begin{comment}
A Pareto priority queue ensures that that the next task to be executed is a Pareto optimum, i.e., a task for which the partial solution is not dominated by the partial solution of any other task - from MW diss
\end{comment}


\section{Shortest path problems} \label{sec:shortest_path}
% Informally introduce shortest path
The problem of finding a shortest path between two nodes in a graph is a classical problem in computer science with numerous practical applications, such as finding the quickest route from location A to location B.
% Introduce the problem of msp
While the \emph{shortest-path problem} minimizes for a single criteria, e.g., the travel time, in practical applications one often wants to optimize multiple -- and possibly conflicting -- objectives:
When searching for a route from A to B, we may want to minimize the travel time as well as toll costs.
In such a setting, we usually cannot give a single best solution anymore. 
Instead, we can give several reasonable solutions: 
The fastest route will usually use highways, thus increasing the toll costs, while a slightly slower route may reduce the toll costs by avoiding highways. 
Problems like this can be modeled as \emph{multi-criteria shortest path} (MSP) problems, where we are interested in all optimal alternatives, i.e., in routes that are \emph{Pareto-optimal}. 
A route from A to B is Pareto-optimal if there is no other route with less or equal cost for each of the $d$ criteria.

% Applications
Apart from the problem of finding an optimal route in a road map as outlined above, the MSP problem has numerous outer applications, such as routing in multimedia networks \cite{ClimacoCP03} \todo{more applications?}

% Hardness of the problem, reason for parallelization
Note that the graph instances resulting from modeling practical problems are potentially very large. 
While the MSP is NP-hard in general, even for $d=2$ \cite{GareyJ79}, it was shown that the problem is feasible for many practically relevant instances \cite{Muller-HannemannW01}.
However, due to the potentially very large graph instances resulting from modeling e.g., road or railway networks, the computational cost is significant even if a small number of criteria is to be optimized \cite{GuerrieroM01}.
Guerriero and Musmanno \cite{GuerrieroM01} thus suggest that parallel computing might help to design efficient solution methods. 

% Sanders, Erb: first parallel MSP algo, but mostly for d=2
To the best of our knowledge, Sanders and Mandow \cite{SM13} published the first proposal of a parallel algorithm for the MSP by extending Dijkstra's classical algorithm \cite{Dijkstra59}.
Their approach relies on a so called \emph{Pareto queue}, a multi-dimensional generalization of a priority queue. 
While they give a high level description of the algorithm for arbitrary $d \geq 2$ and a detailed description of the bi-criteria case (which was further engineered by Erb \cite{Erb13}), they also state that efficient priority queues for $d\geq3$ are not yet known.


\subsection{Definitions and notation} \label{sec:shortest_path:defs}
We provide definitions for variations of the shortest path problems considered in this report. 
The classic text book by Cormen et al.~\cite{CLRS01} provides a more detailed introduction to basic shortest path problems and algorithms.

% Define single-source shortest path
\subsubsection{The classical shortest path problem} \label{sec:shortest_path:defs:sssp}
We are given a weighted directed graph $G=(V,A)$, where $V= \{v_1, v_2, \dots, v_n\}$ is a finite set of nodes, $A \subseteq V \times V$ is a finite set of arcs (directed edges) and $c: A \rightarrow \mathbb{N}$ is the cost or weight function. 
W.l.o.g., we assume that $G$ is a connected graph.
Let $p = \langle v_0, a_1, v_1, a_2, \dots,a_k, v_k \rangle$ be a path from $v_0$ to $v_k$ in $G$ and $P$ be the set of all paths in $G$.
We define the weight $w(p)$ of a path $p$ as 
\begin{align*}
w: P &\rightarrow \mathbb{N} \\
p &\mapsto w(p) = \sum_{i=1}^{k}c(a_i) \quad , \neqn{eg:foo:1}
\end{align*}
i.e., the sum of costs all the arcs in the path $p$.

% Variations: Single source, all-pairs,... shortest path
In a \emph{single-source shortest path problem (SSSP)}, we want to compute a shortest path w.r.t.~some weight function $w$ from a given source node $s \in V$ to each node $v \in V$.
Different variations of the problem exist, such as the \emph{single-destination}, the \emph{single-pair} or the \emph{all-pairs} shortest path problem. 
Note that an optimal algorithm for the SSSP can easily be turned into an optimal algorithm for the first two variants \cite{CLRS01}.
Thus, we will only deal with the SSSP in this report.

\subsubsection{Multi-criteria shortest path (MSP)} \label{sec:shortest_path:defs:msp}
%MSP
Multi-criteria shortest path problems \cite{Martins84} generalize shortest path problems w.r.t.~the weight function $c$, which is extended to $d$-dimensional vectors, i.e., $\vect{c}: A \rightarrow \mathbb{N}^d$ and
\begin{align*}
\vect{w}: P &\rightarrow \mathbb{N}^d \\
p &\mapsto \vect{w}(p) = (w_1(p), w_2(p), \dots , w_d(p)) \quad , \neqn{eg:foo:2}
\end{align*}
where $w_j(p) = \sum_{i=1}^{k}c_j(a_i)$ $\forall j \in \{1,\dots,d\}$.

%Domination relation
Let $\vect{x}$ and $\vect{y}$ be two vectors of dimension $d$, i.e., $\vect{x}, \vect{y} \in \mathbb{N}^d$ and $\vect{x} \neq \vect{y}$. 
We say that $\vect{x}$ \emph{dominates} $\vect{y}$ ($\vect{x} \prec \vect{y}$) -- or equivalently, $\vect{y}$ \emph{is dominated by} $\vect{x}$ -- if and only if
\begin{align}
\forall j \in \{1,\dots, d\}: w_j(x) \leq w_j(y) \quad .
\end{align}
Note that the dominance relation ($\prec$) does not define a total ordering in $\mathbb{R}^d$ for $d\geq 2$.
Thus, there exist vectors $\vect{x}, \vect{y} \in \mathbb{N}^d$, $\vect{x} \neq \vect{y}$ for which neither $\vect{x} \prec \vect{y}$ nor $\vect{y} \prec \vect{x}$ holds.

% Notes
A path $p$ from node $v_1$ to node $v_2$ is a \emph{Pareto-optimal} or \emph{non-dominated} path if there is no path $q \in P$ from $v_1$ to $v_2$ s.t.~$q \prec p$.
Informally, we also call a Pareto-optimal path $p$ \emph{shortest path}.
Thus, for the MSP, the solution consists of a set of Pareto-optimal paths for each considered pair of nodes.




\subsubsection{Mutligraphs} \label{sec:shortest_path:defs:multigraph}
% TODO: we could explain that our solution works on multi graphs too

\section{Pheet} \label{sec:pheet}

\subsection{Task parallelism} \label{sec:pheet:task_parallelism}

\subsection{Priority scheduling} \label{sec:pheet:priority_sched}


\section{Multi-criteria shortest path} \label{sec:msp_algo}
\todo{Our algorithm for the MSP. The algorithm works independently of the scheduler}

\section{Using the StrategyScheduler/linear combination} \label{sec:strategyScheduler}
\todo{\cite{MartinsPRS07} has a theorem showing that linear combination is a valid choice, but probably better to cite \cite{PaixaoS13}.}

\section{Multi-criteria priority queue} \label{sec:mcpq}
\todo{Description and analysis of: virtual array, log-structured list, put/pop, top, steal,\dots}

\section{Performance evaluation} \label{sec:performance}
\subsection{Methodology} \label{sec:performance:methodology}

\section{Conclusion} \label{sec:conclusion}

\section{Acknowledgements} \label{sec:ack}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotPerformanceVariance(
"../benchmarks/mars/g_2000_13000_3_10000_42/with_lincomb/s2pareto.dat", from=1, to=3)
@
\end{center}
\caption{Performance with linear combination in Strategy2TaskStrategy::prioritize (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotPerformanceVariance(
"../benchmarks/mars/g_2000_13000_3_10000_42/with_lincomb/s2pareto.dat", from=4, to=80)
@
\end{center}
\caption{Performance with linear combination in Strategy2TaskStrategy::prioritize (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotPerformanceVariance(
"../benchmarks/mars/g_2000_13000_3_10000_42/without_lincomb/s2pareto.dat", from=1, to=3)
@
\end{center}
\caption{Performance without linear combination in Strategy2TaskStrategy::prioritize (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotPerformanceVariance(
"../benchmarks/mars/g_2000_13000_3_10000_42/without_lincomb/s2pareto.dat", from=4, to=80)
@
\end{center}
\caption{Performance without linear combination in Strategy2TaskStrategy::prioritize (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus(
"../benchmarks/mars/g_2000_13000_3_10000_42/with_lincomb/s2pareto.dat","../benchmarks/mars/g_2000_13000_3_10000_42/without_lincomb/s2pareto.dat", yAxis="total_time", splitBy="comment", from=8, to=80)
@
\end{center}
\caption{Influence of linear combination in Strategy2TaskStrategy::prioritize; min over 10 runs (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus(
"../benchmarks/mars/g_2000_13000_3_10000_42/with_lincomb/s2pareto.dat","../benchmarks/mars/g_2000_13000_3_10000_42/without_lincomb/s2pareto.dat", yAxis="total_time", splitBy="comment", aggFun=mean)
@
\end{center}
\caption{Influence of linear combination in Strategy2TaskStrategy::prioritize; avg over 10 runs (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/mars/g_2000_13000_3_10000_42/improved_pop/before.dat","../benchmarks/mars/g_2000_13000_3_10000_42/improved_pop/after.dat", xAxis="cpus", yAxis="total_time", splitBy="comment")
@
\end{center}
\caption{Improved PLTSBlock::pop (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/mars/g_2000_13000_3_10000_42/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/s2klsm.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/s2lsm.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/improved_put/s2pareto.dat", xAxis="cpus", yAxis="total_time", splitBy="comment")
@
\end{center}
\caption{Improved PLTSBlock::put (g\_2000\_13000\_3\_10000\_42)}
\end{figure}


\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/mars/g_2000_13000_3_10000_42/strategy.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/s2klsm.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/s2lsm.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/s2pareto.dat", xAxis="cpus", yAxis="total_time", splitBy="algorithm")
@
\end{center}
\caption{Abs.\ performance over nr.\ cpus (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/local/g_2000_13000_3_10000_42/baseline/strategy.dat", "../benchmarks/local/g_2000_13000_3_10000_42/baseline/strategy2.dat", xAxis="cpus", yAxis="total_time", splitBy="algorithm")
@
\end{center}
\caption{Abs.\ performance over nr.\ cpus (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/mars/g_2000_13000_3_10000_42/mo_seq_cst/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_aq_rel/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_relaxed/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/strategy.dat", xAxis="cpus", yAxis="total_time", splitBy="comment")
@
\end{center}
\caption{Influence of memory order (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus(
"../benchmarks/mars/g_2000_13000_3_10000_42/mo_seq_cst/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_aq_rel/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_relaxed/strategy2.dat", yAxis="total_time", splitBy="comment", from=1, to=4)
@
\end{center}
\caption{Influence of memory order, \#cpus=1-4 (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus("../benchmarks/mars/g_2000_13000_3_10000_42/mo_seq_cst/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_aq_rel/strategy2.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/mo_relaxed/strategy2.dat", yAxis="total_time", splitBy="comment", from=4, to=80)
@
\end{center}
\caption{Influence of memory order, \#cpus=4-80  (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark(
"../benchmarks/local/g_2000_13000_3_10000_42/max_partition_8/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_16/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_32/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_64/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_128/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_256/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_512/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_1024/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/max_partition_4096/strategy2.dat",
"../benchmarks/local/g_2000_13000_3_10000_42/baseline/strategy2.dat", xAxis="cpus", yAxis="total_time", splitBy="comment")
@
\end{center}
\caption{Influence of MAX\_PARTITION\_SIZE (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus("../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/16/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/32/s2pareto.dat",
"../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/64/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/128/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/256/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/512/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/1024/s2pareto.dat",
yAxis="total_time", splitBy="comment", from=1, to=3)
@
\end{center}
\caption{Influence of MAX\_PARTITION\_SIZE (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus("../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/16/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/32/s2pareto.dat",
"../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/64/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/128/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/256/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/512/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/1024/s2pareto.dat",
yAxis="total_time", splitBy="comment", from=4, to=7)
@
\end{center}
\caption{Influence of MAX\_PARTITION\_SIZE (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotOverCpus("../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/16/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/32/s2pareto.dat",
"../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/64/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/128/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/256/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/512/s2pareto.dat", "../benchmarks/mars/g_2000_13000_3_10000_42/MAX_PARTITION_SIZE/1024/s2pareto.dat",
yAxis="total_time", splitBy="comment", from=8, to=80)
@
\end{center}
\caption{Influence of MAX\_PARTITION\_SIZE (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

\begin{figure}
\begin{center}
<<fig=TRUE, echo=FALSE>>=
plotBenchmark("../benchmarks/local/g_2000_13000_3_10000_42/max_partition_128/strategy2.dat", "../benchmarks/local/g_2000_13000_3_10000_42/baseline/strategy.dat", xAxis="cpus", yAxis="total_time", splitBy="algorithm")
@
\end{center}
\caption{Strategy2 with MAX\_PARTITION\_SIZE=128 vs.~Strategy (g\_2000\_13000\_3\_10000\_42)}
\end{figure}

%bibliography
\bibliographystyle{acm}
\bibliography{sources} 
\end{document}

  